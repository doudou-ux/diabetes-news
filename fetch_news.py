# fetch_news.py
import datetime
import html
import os
import time # ç”¨äºæ—¥æœŸè½¬æ¢
import requests
import feedparser # ç”¨äºè§£æRSS feeds
from bs4 import BeautifulSoup # ç”¨äºæ¸…ç†HTMLæ ‡ç­¾

# --- é…ç½®èµ„è®¯åˆ†ç±» ---
# å…³é”®å­—å°†ç”¨äºæ„å»º Google News RSS æŸ¥è¯¢
CATEGORIES_CONFIG = {
    "æœ€æ–°ç ”ç©¶": {"keywords": "ç³–å°¿ç—… æœ€æ–°ç ”ç©¶", "emoji": "ğŸ”¬"},
    "æ²»ç–—è¿›å±•": {"keywords": "ç³–å°¿ç—… æ²»ç–—è¿›å±•", "emoji": "ğŸ’Š"},
    "é¢„é˜²ä¸ç”Ÿæ´»æ–¹å¼": {"keywords": "ç³–å°¿ç—… é¢„é˜² ç”Ÿæ´»æ–¹å¼", "emoji": "ğŸƒâ€â™€ï¸"},
    "å¹¶å‘ç—‡ç®¡ç†": {"keywords": "ç³–å°¿ç—… å¹¶å‘ç—‡ç®¡ç†", "emoji": "ğŸ©º"},
    "é¥®é£Ÿä¸è¥å…»": {"keywords": "ç³–å°¿ç—… é¥®é£Ÿè¥å…»", "emoji": "ğŸ¥—"}
}

# --- å¸®åŠ©å‡½æ•°ï¼šåˆ¤æ–­æ—¥æœŸæ˜¯å¦åœ¨æœ¬å‘¨ ---
def is_this_week_rss(time_struct, today_date_obj):
    return True # ä¸´æ—¶æµ‹è¯•ï¼Œä¸è¿‡æ»¤æ—¥æœŸ
def is_this_week_rss(time_struct, today_date_obj):
    """
    åˆ¤æ–­ç»™å®šçš„ time_struct (æ¥è‡ª feedparser) æ˜¯å¦åœ¨æœ¬å‘¨ (å‘¨ä¸€åˆ°å‘¨æ—¥)ã€‚
    today_date_obj æ˜¯ä»Šå¤©çš„ datetime.date å¯¹è±¡ã€‚
    """
    if not time_struct:
        return False
    try:
        # feedparser è¿”å›çš„ time_struct æ˜¯ time.struct_time å¯¹è±¡
        article_date = datetime.date(time_struct.tm_year, time_struct.tm_mon, time_struct.tm_mday)
        
        # è®¡ç®—æœ¬å‘¨çš„å¼€å§‹ (å‘¨ä¸€) å’Œç»“æŸ (å‘¨æ—¥)
        start_of_week = today_date_obj - datetime.timedelta(days=today_date_obj.weekday())
        end_of_week = start_of_week + datetime.timedelta(days=6)
        
        return start_of_week <= article_date <= end_of_week
    except Exception as e:
        print(f"    [is_this_week_rss] æ—¥æœŸè½¬æ¢é”™è¯¯: {e} - Time Struct: {time_struct}")
        return False # å¦‚æœæ—¥æœŸæ— æ•ˆæˆ–è§£æå¤±è´¥

# --- å¸®åŠ©å‡½æ•°ï¼šæ¸…ç† HTML ---
def clean_html(raw_html):
    """ä½¿ç”¨ BeautifulSoup æ¸…ç† HTML æ ‡ç­¾"""
    if not raw_html:
        return ""
    try:
        soup = BeautifulSoup(raw_html, "html.parser")
        return soup.get_text()
    except Exception as e:
        print(f"    [clean_html] HTML æ¸…ç†é”™è¯¯: {e}")
        return raw_html # å‡ºé”™åˆ™è¿”å›åŸå§‹æ–‡æœ¬

# --- ä» Google News RSS è·å–çœŸå®æ–°é—» ---
def fetch_real_news_from_google_rss(category_name, keywords_for_rss):
    """
    ä» Google News RSS feed è·å–æŒ‡å®šåˆ†ç±»çš„æ–°é—»ã€‚
    """
    print(f"  æ­£åœ¨ä¸ºåˆ†ç±» '{category_name}' (å…³é”®è¯: '{keywords_for_rss}') è·å–çœŸå®æ–°é—»...")
    base_url = "https://news.google.com/rss/search"
    query_params = {
        "q": keywords_for_rss,
        "hl": "zh-CN", 
        "gl": "CN",    
        "ceid": "CN:zh-Hans" 
    }
    
    articles_this_week = []
    today = datetime.date.today()

    try:
        headers = { 
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(base_url, params=query_params, headers=headers, timeout=15) 
        response.raise_for_status() 

        feed = feedparser.parse(response.content)
        
        if not feed.entries:
            print(f"    æœªæ‰¾åˆ°åˆ†ç±» '{category_name}' çš„æ–°é—»æ¡ç›®ã€‚")
            return []

        print(f"    åˆ†ç±» '{category_name}' åŸå§‹è·å–åˆ° {len(feed.entries)} æ¡æ–°é—»ï¼Œå¼€å§‹ç­›é€‰æœ¬å‘¨æ–°é—»...")

        for entry in feed.entries:
            title = entry.get("title", "æ— æ ‡é¢˜")
            link = entry.get("link", "javascript:void(0);")
            
            published_time_struct = entry.get("published_parsed")
            if not published_time_struct:
                published_time_struct = entry.get("updated_parsed")

            if is_this_week_rss(published_time_struct, today):
                summary_html = entry.get("summary", "æš‚æ— æ‘˜è¦")
                snippet = clean_html(summary_html) 
                
                source_info = entry.get("source")
                source_name = source_info.get("title", "Google News") if source_info else "Google News"

                time_display_str = "æœªçŸ¥æ—¶é—´"
                if published_time_struct:
                    try:
                        time_display_str = time.strftime("%Y-%m-%d", published_time_struct)
                    except:
                        pass 

                articles_this_week.append({
                    "title": title,
                    "url": link,
                    "snippet": snippet,
                    "source": source_name,
                    "time": time_display_str 
                })
                if len(articles_this_week) >= 10: 
                    break 
        
        print(f"    åˆ†ç±» '{category_name}' ç­›é€‰åå¾—åˆ° {len(articles_this_week)} æ¡æœ¬å‘¨æ–°é—»ã€‚")

    except requests.exceptions.RequestException as e:
        print(f"    è·å–åˆ†ç±» '{category_name}' æ–°é—»æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}")
    except Exception as e:
        print(f"    å¤„ç†åˆ†ç±» '{category_name}' æ–°é—»æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        
    return articles_this_week


# --- HTML ç”Ÿæˆé€»è¾‘ ---
def generate_html_content(all_news_data):
    """æ ¹æ®æ–°é—»æ•°æ®ç”Ÿæˆå®Œæ•´çš„HTMLé¡µé¢å†…å®¹"""
    current_time_str = datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
    app_timezone = os.getenv('APP_TIMEZONE', 'UTC') 
    if app_timezone != 'UTC':
        try:
             # å‡è®¾ä¸œå…«åŒºï¼Œæ›´ç²¾ç¡®çš„å®ç°å¯èƒ½éœ€è¦pytz
             current_time_str = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=8))).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S %Z')
        except Exception as e:
            print(f"åº”ç”¨æ—¶åŒº ({app_timezone}) æ—¶å‡ºé”™: {e}ã€‚å°†ä½¿ç”¨é»˜è®¤æœåŠ¡å™¨æ—¶é—´ã€‚")
            current_time_str = datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S (æœåŠ¡å™¨æ—¶é—´)')

    current_year = datetime.datetime.now().year
    github_repo_url = f"https://github.com/{os.getenv('GITHUB_REPOSITORY', 'YOUR_USERNAME/YOUR_REPOSITORY_NAME')}"

    html_output = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç³–å°¿ç—…å‰æ²¿èµ„è®¯</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        body {{ font-family: 'Inter', sans-serif; background-color: #f0f4f8; }}
        .news-card {{ transition: transform 0.3s ease, box-shadow 0.3s ease; display: flex; flex-direction: column; justify-content: space-between; height: 100%; background-color: #ffffff; border-radius: 0.5rem; }}
        .news-card:hover {{ transform: translateY(-5px); box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05); }}
        .category-section {{ background-color: #ffffff; border-radius: 0.75rem; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); padding: 1.25rem; }}
        @media (min-width: 768px) {{ .category-section {{ padding: 2rem; }} }}
        .category-title-text {{ border-bottom: 3px solid #3b82f6; padding-bottom: 0.75rem; margin-bottom: 1.75rem; color: #1e40af; font-size: 1.5rem; }}
        @media (min-width: 768px) {{ .category-title-text {{ font-size: 1.875rem; }} }}
        .news-item-link {{ color: #2563eb; text-decoration: none; font-weight: 600; }}
        .news-item-link:hover {{ text-decoration: underline; color: #1d4ed8; }}
        .source-tag, .time-tag {{ padding: 0.25rem 0.75rem; border-radius: 0.375rem; font-size: 0.75rem; font-weight: 500; line-height: 1.25; }}
        .source-tag {{ background-color: #e0e7ff; color: #3730a3; }}
        .time-tag {{ background-color: #d1fae5; color: #065f46; }}
        .card-content {{ flex-grow: 1; }}
        .card-footer {{ margin-top: auto; }}
        .header-main-title {{ font-size: 1.875rem; }}
        @media (min-width: 640px) {{ .header-main-title {{ font-size: 2.25rem; }} }}
        @media (min-width: 768px) {{ .header-main-title {{ font-size: 3rem; }} }}
        .main-container {{ padding: 1rem; }}
        @media (min-width: 768px) {{ .main-container {{ padding: 2rem; }} }}
        .loader {{ border: 5px solid #f3f3f3; border-radius: 50%; border-top: 5px solid #3498db; width: 50px; height: 50px; -webkit-animation: spin 1s linear infinite; animation: spin 1s linear infinite; margin: 20px auto; }}
        @-webkit-keyframes spin {{ 0% {{ -webkit-transform: rotate(0deg); }} 100% {{ -webkit-transform: rotate(360deg); }} }}
        @keyframes spin {{ 0% {{ transform: rotate(0deg); }} 100% {{ transform: rotate(360deg); }} }}
    </style>
</head>
<body class="bg-gray-100 text-gray-800">
    <div class="container mx-auto main-container">
        <header class="text-center mb-10 md:mb-16">
            <h1 class="font-bold text-blue-700 header-main-title">ç³–å°¿ç—…å‰æ²¿èµ„è®¯</h1>
            <p class="text-gray-600 mt-3 text-base md:text-lg">æœ¬å‘¨æœ€æ–°åŠ¨æ€ï¼ˆè‡ªåŠ¨æ›´æ–°äºï¼š<span id="updateTime">{current_time_str}</span>ï¼‰</p>
            <p class="text-sm text-gray-500 mt-2">èµ„è®¯æ¥æºï¼šGoogle News RSS Feeds</p>
        </header>
        <div id="news-content" class="space-y-12">
            <div id="loading-indicator" class="text-center py-10">
                 <div class="loader"></div>
                 <p class="text-gray-600 mt-2">æ­£åœ¨åŠ è½½æœ€æ–°èµ„è®¯...</p>
            </div>
        </div>
    </div>
    <footer class="text-center p-6 mt-12 text-gray-600 text-sm border-t border-gray-300">
        <p>&copy; {current_year} ç³–å°¿ç—…èµ„è®¯èšåˆ. <a href="{github_repo_url}" target="_blank" rel="noopener noreferrer" class="text-blue-600 hover:underline">é¡¹ç›®æºç </a></p>
        <p class="mt-1">æœ¬ç«™å†…å®¹ä»…ä¾›å‚è€ƒ, ä¸æ„æˆåŒ»ç–—å»ºè®®ã€‚</p>
    </footer>
    <script>
        document.addEventListener('DOMContentLoaded', function() {{
            const newsContent = document.getElementById('news-content');
            const loadingIndicator = document.getElementById('loading-indicator');
            let hasRealContent = false;
            if (newsContent && newsContent.childNodes) {{ // æ·»åŠ æ£€æŸ¥ä»¥ç¡®ä¿ newsContent å’Œ childNodes å­˜åœ¨
                for (let i = 0; i < newsContent.childNodes.length; i++) {{
                    if (newsContent.childNodes[i].id !== 'loading-indicator' && newsContent.childNodes[i].nodeType === 1) {{
                        hasRealContent = true;
                        break;
                    }}
                }}
            }}
            if (loadingIndicator && hasRealContent) {{
                // loadingIndicator.style.display = 'none'; 
            }} else if (loadingIndicator && newsContent && newsContent.textContent && newsContent.textContent.includes("æœªèƒ½åŠ è½½")) {{ // æ·»åŠ å¯¹ newsContent å’Œ textContent çš„æ£€æŸ¥
                // å¦‚æœ åªæœ‰ é”™è¯¯ ä¿¡æ¯ , ä¹Ÿ ç§»é™¤ åŠ è½½ åŠ¨ç”»  // <--- ä¿®æ­£è¿™é‡Œçš„æ³¨é‡Šä¸ºåŠè§’æ–œæ 
                loadingIndicator.style.display = 'none';
            }}
        }});
    </script>
</body>
</html>"""

    news_html_parts = []
    found_any_news = False

    if not all_news_data or all(not articles for articles in all_news_data.values()):
        news_html_parts.append('<p class="text-center text-gray-500 text-xl py-10">æŠ±æ­‰ï¼Œç›®å‰æœªèƒ½åŠ è½½åˆ°æœ¬å‘¨ç›¸å…³çš„ç³–å°¿ç—…èµ„è®¯ã€‚</p>')
    else:
        for category, articles in all_news_data.items():
            category_emoji = CATEGORIES_CONFIG.get(category, {}).get("emoji", "")
            category_html = f"""
            <section class="category-section">
                <h2 class="font-semibold category-title-text">{category_emoji} {html.escape(category)}</h2>
            """
            if not articles:
                category_html += '<p class="text-gray-500">æœ¬å‘¨æš‚æ— è¯¥åˆ†ç±»ä¸‹çš„èµ„è®¯ã€‚</p>'
            else:
                found_any_news = True
                category_html += '<div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6 md:gap-8 news-grid">'
                for article in articles: 
                    title = html.escape(article.get('title', 'æ— æ ‡é¢˜'))
                    url = html.escape(article.get('url', 'javascript:void(0);'))
                    snippet_raw = article.get('snippet', 'æš‚æ— æ‘˜è¦')
                    snippet = html.escape(snippet_raw[:150] + ('...' if len(snippet_raw) > 150 else ''))
                    source = html.escape(article.get('source', 'æœªçŸ¥æ¥æº'))
                    time_display = html.escape(article.get('time', 'æœªçŸ¥æ—¶é—´'))

                    category_html += f"""
                    <div class="news-card shadow-md hover:shadow-lg p-5">
                        <div class="card-content">
                            <h3 class="text-lg mb-2">
                                <a href="{url}" {'target="_blank" rel="noopener noreferrer"' if url != 'javascript:void(0);' else ''} class="news-item-link">
                                    {title}
                                </a>
                            </h3>
                            <p class="text-gray-600 text-sm mb-4 leading-relaxed">{snippet}</p>
                        </div>
                        <div class="card-footer text-xs text-gray-500 flex flex-wrap gap-2 items-center pt-3 border-t border-gray-200">
                            <span class="source-tag">{source}</span>
                            <span class="time-tag">{time_display}</span>
                        </div>
                    </div>
                    """
                category_html += "</div>" 
            category_html += "</section>"
            news_html_parts.append(category_html)
    
    # æ›¿æ¢HTMLæ¨¡æ¿ä¸­çš„å ä½ç¬¦
    # ç¡®ä¿ loading-indicator å­˜åœ¨æ‰å°è¯•æ›¿æ¢å®ƒ
    loading_indicator_html = """<div id="loading-indicator" class="text-center py-10">
                 <div class="loader"></div>
                 <p class="text-gray-600 mt-2">æ­£åœ¨åŠ è½½æœ€æ–°èµ„è®¯...</p>
            </div>"""
    if loading_indicator_html in html_output:
        if found_any_news or (news_html_parts and "<p class=\"text-center text-gray-500 text-xl py-10\">" in news_html_parts[0]):
            html_output = html_output.replace(loading_indicator_html, "".join(news_html_parts))
        # å¦‚æœæ²¡æœ‰æ–°é—»ï¼Œä¹Ÿæ²¡æœ‰é”™è¯¯ä¿¡æ¯ï¼ˆç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼Œå› ä¸ºä¸Šé¢å·²å¤„ç† all_news_data ä¸ºç©ºçš„æƒ…å†µï¼‰ï¼Œ
        # å¹¶ä¸” news_html_parts ä¸ºç©ºï¼Œåˆ™ä¿ç•™åŠ è½½æŒ‡ç¤ºå™¨æˆ–æ˜¾ç¤ºé€šç”¨é”™è¯¯ã€‚
        # ä¸ºäº†å®‰å…¨èµ·è§ï¼Œå¦‚æœ news_html_parts ä¸ºç©ºä½† found_any_news ä¸º falseï¼Œ
        # å¹¶ä¸”æ²¡æœ‰æ˜ç¡®çš„â€œæœªèƒ½åŠ è½½â€ä¿¡æ¯ï¼Œåˆ™ä¹Ÿæ›¿æ¢æ‰åŠ è½½æŒ‡ç¤ºå™¨ï¼Œä»¥é˜²ä¸‡ä¸€ã€‚
        elif not news_html_parts: # å¦‚æœ news_html_parts æ˜¯ç©ºçš„
             html_output = html_output.replace(loading_indicator_html, '<p class="text-center text-gray-500 text-xl py-10">èµ„è®¯åŠ è½½æ—¶å‡ºç°é—®é¢˜æˆ–æš‚æ— å†…å®¹ã€‚</p>')

    else: # å¦‚æœæ¨¡æ¿ä¸­æ²¡æœ‰åŠ è½½æŒ‡ç¤ºå™¨äº†ï¼ˆæ¯”å¦‚ä¹‹å‰çš„æ›¿æ¢é€»è¾‘ä¸å®Œç¾ï¼‰ï¼Œç›´æ¥æ„å»ºæ–°é—»å†…å®¹åŒº
        html_output = html_output.replace(
            '<div id="news-content" class="space-y-12">\n            \n            ',
            f'<div id="news-content" class="space-y-12">\n{"".join(news_html_parts)}'
        )


    return html_output

# --- ä¸»æ‰§è¡Œé€»è¾‘ ---
if __name__ == "__main__":
    print("å¼€å§‹ä» Google News RSS ç”Ÿæˆç³–å°¿ç—…èµ„è®¯ç½‘é¡µ...")
    all_news_data_for_html = {}

    for category_name_zh, config in CATEGORIES_CONFIG.items():
        articles = fetch_real_news_from_google_rss(category_name_zh, config["keywords"])
        all_news_data_for_html[category_name_zh] = articles
        print(f"  åˆ†ç±» '{category_name_zh}' å¤„ç†å®Œæ¯•ï¼Œè·å–åˆ° {len(articles)} æ¡æœ¬å‘¨æ–°é—»ã€‚")
        time.sleep(1) 
    
    final_html = generate_html_content(all_news_data_for_html)
    
    output_filename = "index.html" 
    try:
        with open(output_filename, "w", encoding="utf-8") as f:
            f.write(final_html)
        print(f"æˆåŠŸç”Ÿæˆç½‘é¡µï¼š{output_filename}")
    except IOError as e:
        print(f"é”™è¯¯ï¼šæ— æ³•å†™å…¥æ–‡ä»¶ {output_filename}ã€‚é”™è¯¯ä¿¡æ¯: {e}")
    except Exception as e:
        print(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    print("èµ„è®¯ç½‘é¡µç”Ÿæˆå®Œæ¯•ã€‚")

