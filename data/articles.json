[
  {
    "id": 1752666063384,
    "title": "构建有效的AI智能体",
    "url": "",
    "description": "暂无描述",
    "content": "发布于2024年12月19日\n\n我们与数十个跨行业构建LLM智能体的团队合作过。一致的发现是，最成功的实现使用的是简单、可组合的模式，而不是复杂的框架。\n\n在过去一年中，我们与数十个跨行业构建大语言模型(LLM)智能体的团队合作。一致的发现是，最成功的实现并没有使用复杂的框架或专门的库，而是使用简单、可组合的模式进行构建。\n\n在这篇文章中，我们分享了从与客户合作和自己构建智能体中学到的经验，并为开发者提供构建有效智能体的实用建议。\n\n什么是智能体？\n\n\"智能体\"可以有多种定义。一些客户将智能体定义为完全自主的系统，能够在较长时间内独立运行，使用各种工具来完成复杂任务。其他人则用这个术语来描述遵循预定义工作流程的更规范化的实现。在Anthropic，我们将所有这些变体归类为智能体系统，但在工作流程和智能体之间划分了重要的架构区别：\n\n工作流程是通过预定义代码路径编排LLM和工具的系统。\n智能体则是LLM动态指导自己的流程和工具使用，保持对如何完成任务的控制权的系统。\n\n下面，我们将详细探讨这两种类型的智能体系统。在附录1（\"实践中的智能体\"）中，我们描述了客户发现这些系统特别有价值的两个领域。\n\n何时（以及何时不）使用智能体\n\n在使用LLM构建应用程序时，我们建议寻找尽可能简单的解决方案，只有在需要时才增加复杂性。这可能意味着根本不构建智能体系统。智能体系统通常会以延迟和成本换取更好的任务性能，您应该考虑这种权衡何时有意义。\n\n当需要更高复杂性时，工作流程为明确定义的任务提供可预测性和一致性，而当需要灵活性和模型驱动的决策制定时，智能体是更好的选择。然而，对于许多应用程序来说，通过检索和上下文示例优化单个LLM调用通常就足够了。\n\n何时以及如何使用框架\n\n有许多框架使智能体系统更容易实现，包括：\n\n●LangChain的LangGraph\n●Amazon Bedrock的AI智能体框架\n●Rivet，一个拖放式GUI LLM工作流构建器\n●Vellum，另一个用于构建和测试复杂工作流程的GUI工具\n\n这些框架通过简化标准的低级任务（如调用LLM、定义和解析工具、链接调用等）使入门变得容易。然而，它们经常创建额外的抽象层，可能会模糊底层的提示和响应，使其更难调试。它们也可能诱使开发者在简单设置就足够时添加复杂性。\n\n我们建议开发者直接从使用LLM API开始：许多模式可以用几行代码实现。如果您确实使用框架，请确保理解底层代码。对底层机制的错误假设是客户错误的常见来源。\n\n请参阅我们的cookbook获取一些示例实现。\n\n构建块、工作流程和智能体\n\n在本节中，我们将探索在生产中看到的智能体系统的常见模式。我们将从基础构建块——增强LLM开始，逐步增加复杂性，从简单的组合工作流程到自主智能体。\n\n构建块：增强LLM\n\n智能体系统的基本构建块，是通过检索、工具和记忆等，增强功能强化的LLM。我们当前的模型可以主动使用这些能力——生成自己的搜索查询、选择适当的工具，并确定保留哪些信息。\n\n\n我们建议专注于实现的两个关键方面：根据您的特定用例定制这些能力，并确保它们为您的LLM提供易于使用、文档完善的接口。虽然有多种方法来实现这些增强功能，但一种方法是通过我们最近发布的模型上下文协议(Model Context Protocol)，它允许开发者通过简单的客户端实现与不断增长的第三方工具生态系统集成。\n\n在本文的其余部分，我们假设每个LLM调用都可以访问这些增强能力。\n\n工作流程：提示链\n\n提示链将任务分解为一系列步骤，其中每个LLM调用处理前一个调用的输出。您可以在任何中间步骤添加程序化检查（见下图中的\"gate\"），以确保流程仍在正轨上。\n\n\n\n何时使用此工作流程：此工作流程适用于可以轻松、清晰地分解为固定子任务的情况。主要目标是用延迟换取更高的准确性，通过使每个LLM调用成为更容易的任务。\n\n提示链有用的示例：\n●生成营销文案，然后将其翻译成不同语言\n●写文档大纲，检查大纲是否符合某些标准，然后基于大纲写文档\n\n工作流程：路由\n\n路由对输入进行分类并将其定向到专门的后续任务。此工作流程允许关注点分离，并构建更专门化的提示。没有此工作流程，针对一种输入的优化可能会损害其他输入的性能。\n\n\n\n何时使用此工作流程：路由适用于有明显类别的复杂任务，这些类别最好分别处理，并且分类可以通过LLM或更传统的分类模型/算法准确处理。\n\n路由有用的示例：\n●将不同类型的客户服务查询（一般问题、退款请求、技术支持）导向不同的下游流程、提示和工具\n●将简单/常见问题路由到较小的模型如Claude 3.5 Haiku，将困难/不寻常的问题路由到更强大的模型如Claude 3.5 Sonnet，以优化成本和速度\n\n工作流程：并行化\n\nLLM有时可以同时处理任务并以程序化方式聚合其输出。这种工作流程，即并行化，表现为两种关键变体：\n\n分段：将任务分解为并行运行的独立子任务\n投票：多次运行相同任务以获得多样化输出\n\n\n\n何时使用此工作流程：当分割的子任务可以并行化以提高速度，或当需要多个观点或尝试以获得更高置信度结果时，并行化是有效的。对于具有多个考虑因素的复杂任务，LLM在每个考虑因素由单独的LLM调用处理时通常表现更好，允许对每个特定方面进行集中关注。\n\n并行化有用的示例：\n\n分段：\n●实施护栏，其中一个模型实例处理用户查询，而另一个筛选不当内容或请求。这往往比让同一个LLM调用同时处理护栏和核心响应表现更好\n●自动化评估，用于评估LLM性能，其中每个LLM调用评估模型在给定提示上性能的不同方面\n\n投票：\n●审查代码漏洞，其中几个不同的提示审查并标记代码（如果发现问题）\n●评估给定内容是否不当，多个提示评估不同方面或需要不同投票阈值来平衡误报和漏报\n\n工作流程：编排者-工作者\n\n在编排者-工作者工作流程中，中央LLM动态分解任务，将其委托给工作者LLM，并综合其结果。\n\n\n\n何时使用此工作流程：此工作流程适用于无法预测所需子任务的复杂任务（例如，在编码中，需要更改的文件数量和每个文件中更改的性质可能取决于任务）。虽然在拓扑上相似，但与并行化的关键区别在于其灵活性——子任务不是预定义的，而是由编排者根据特定输入确定的。\n\n编排者-工作者有用的示例：\n●每次对多个文件进行复杂更改的编码产品\n●涉及从多个来源收集和分析信息以获取可能相关信息的搜索任务\n\n工作流程：评估者-优化者\n\n在评估者-优化者工作流程中，一个LLM调用生成响应，而另一个在循环中提供评估和反馈。\n\n\n\n何时使用此工作流程：当我们有明确的评估标准，以及迭代改进提供可衡量价值时，此工作流程特别有效。适合性的两个标志是：首先，当人类阐述反馈时，LLM响应可以得到明显改进；其次，LLM可以提供这样的反馈。这类似于人类作家在制作精美文档时可能经历的迭代写作过程。\n\n评估者-优化者有用的示例：\n●文学翻译，其中存在翻译LLM可能最初无法捕捉的细微差别，但评估者LLM可以提供有用的批评\n●需要多轮搜索和分析以收集全面信息的复杂搜索任务，其中评估者决定是否需要进一步搜索\n\n智能体\n\n随着LLM在关键能力方面的成熟——理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复，智能体正在生产中兴起。智能体通过来自人类用户的命令或与人类用户的交互式讨论开始工作。一旦任务明确，智能体就会独立规划和操作，可能会回到人类那里获取进一步的信息或判断。\n\n在执行过程中，智能体在每一步从环境中获得\"真实情况\"（如工具调用结果或代码执行）以评估其进度至关重要。然后智能体可以在检查点或遇到阻碍时暂停以获取人类反馈。任务通常在完成时终止，但通常也包括停止条件（如最大迭代次数）以保持控制。\n\n智能体可以处理复杂任务，但其实现通常是直接的。它们通常只是在循环中基于环境反馈使用工具的LLM。因此，清晰和深思熟虑地设计工具集及其文档至关重要。我们在附录2（\"工具的提示工程\"）中扩展了工具开发的最佳实践。\n\n\n\n\n何时使用智能体：智能体可用于难以或不可能预测所需步骤数的开放性问题，以及无法硬编码固定路径的情况。LLM将可能运行多轮，您必须对其决策制定有一定程度的信任。智能体的自主性使其非常适合在可信环境中扩展任务。\n\n智能体的自主性意味着更高的成本和复合错误的潜力。我们建议在沙盒环境中进行广泛测试，以及适当的护栏。\n\n智能体有用的示例：\n\n以下示例来自我们自己的实现：\n●解决SWE-bench任务的编码智能体，涉及基于任务描述对多个文件进行编辑\n●我们的\"计算机使用\"参考实现，其中Claude使用计算机完成任务\n\n\n\n组合和定制这些模式\n\n这些构建块不是规定性的。它们是开发者可以塑造和组合以适应不同用例的常见模式。与任何LLM功能一样，成功的关键是衡量性能并迭代实现。重申：只有在明显改善结果时，您才应该考虑增加复杂性。\n\n总结\n\nLLM领域的成功不在于构建最复杂的系统，而在于为您的需求构建正确的系统。从简单的提示开始，通过全面评估对其进行优化，只有在简单解决方案不够时才添加多步骤智能体系统。\n\n在实现智能体时，我们尝试遵循三个核心原则：\n\n1. 保持智能体设计的简单性\n2. 通过明确显示智能体的规划步骤来优先考虑透明度\n3. 通过彻底的工具文档和测试仔细制作您的智能体-计算机接口(ACI)\n\n框架可以帮助您快速入门，但在转向生产时，不要犹豫减少抽象层并使用基本组件构建。通过遵循这些原则，您可以创建不仅强大而且可靠、可维护且受用户信任的智能体。\n\n致谢\n\n由Erik Schluntz和Barry Zhang撰写。这项工作借鉴了我们在Anthropic构建智能体的经验以及客户分享的宝贵见解，对此我们深表感谢。\n\n附录1：实践中的智能体\n\n我们与客户的合作揭示了AI智能体的两个特别有前景的应用，展示了上述讨论模式的实用价值。这两个应用都说明了智能体如何为需要对话和行动、有明确成功标准、启用反馈循环并整合有意义的人类监督的任务增加最大价值。\n\nA. 客户支持\n\n客户支持将熟悉的聊天机器人界面与通过工具集成增强的能力相结合。这自然适合更开放的智能体，因为：\n\n●支持交互自然遵循对话流程，同时需要访问外部信息和操作\n●工具可以集成以提取客户数据、订单历史和知识库文章\n●可以程序化处理退款或更新票据等操作\n●成功可以通过用户定义的解决方案清楚地衡量\n\n几家公司通过基于使用的定价模型展示了这种方法的可行性，该模型仅对成功解决方案收费，显示了对其智能体有效性的信心。\n\nB. 编码智能体\n\n软件开发领域显示出LLM功能的显著潜力，能力从代码完成发展到自主问题解决。智能体特别有效，因为：\n\n●代码解决方案可通过自动化测试进行验证\n●智能体可以使用测试结果作为反馈迭代解决方案\n●问题空间定义明确且结构化\n●输出质量可以客观衡量\n\n在我们自己的实现中，智能体现在可以仅基于拉取请求描述解决SWE-bench Verified基准测试中的真实GitHub问题。然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。\n\n附录2：工具的提示工程\n\n无论您构建哪种智能体系统，工具都可能是您智能体的重要组成部分。工具通过在我们的API中指定其确切结构和定义，使Claude能够与外部服务和API交互。当Claude响应时，如果它计划调用工具，API响应中将包含工具使用块。工具定义和规范应该像您的整体提示一样受到提示工程的关注。在这个简短的附录中，我们描述如何对工具进行提示工程。\n\n指定相同操作通常有几种方法。例如，您可以通过编写diff或重写整个文件来指定文件编辑。对于结构化输出，您可以在markdown内或JSON内返回代码。在软件工程中，这些差异是表面的，可以无损地从一种转换为另一种。然而，某些格式对LLM来说比其他格式更难编写。编写diff需要在编写新代码之前知道块头中有多少行在变化。在JSON内编写代码（相比于markdown）需要额外转义换行符和引号。\n\n我们对决定工具格式的建议如下：\n\n●给模型足够的标记来\"思考\"，然后再将自己写入困境\n●保持格式接近模型在互联网文本中自然出现的内容\n●确保没有格式\"开销\"，如必须保持数千行代码的准确计数，或字符串转义任何编写的代码\n\n一个经验法则是考虑在人机界面(HCI)上投入了多少努力，并计划在创建良好的智能体-计算机接口(ACI)上投入同样多的努力。以下是一些如何做到这一点的想法：\n\n●站在模型的角度思考。基于描述和参数，如何使用这个工具是否明显，还是您需要仔细思考？如果是这样，那么对模型来说可能也是如此。一个好的工具定义通常包括示例使用、边缘情况、输入格式要求和与其他工具的清晰边界。\n\n●如何更改参数名称或描述以使事情更明显？将此视为为团队中的初级开发者编写出色的文档字符串。在使用许多相似工具时，这尤其重要。\n\n●测试模型如何使用您的工具：在我们的工作台中运行许多示例输入，看看模型犯了什么错误，并进行迭代。\n\n●对您的工具进行防错设计。更改参数，使其更难出错。\n\n在为SWE-bench构建我们的智能体时，我们实际上花费更多时间优化我们的工具而不是整体提示。例如，我们发现在智能体移出根目录后，模型会在使用相对文件路径的工具上犯错误。为了解决这个问题，我们更改了工具以始终要求绝对文件路径——我们发现模型完美地使用了这种方法。",
    "tags": [
      "AI"
    ],
    "rating": 5,
    "date": "2025-07-16T11:41:03.384Z"
  }
]